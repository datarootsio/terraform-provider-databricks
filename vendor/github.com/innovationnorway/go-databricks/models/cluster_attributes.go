// Code generated by go-swagger; DO NOT EDIT.

package models

// This file was generated by the swagger tool.
// Editing this file might prove futile when you re-run the swagger generate command

import (
	"strconv"

	"github.com/go-openapi/errors"
	strfmt "github.com/go-openapi/strfmt"
	"github.com/go-openapi/swag"
)

// ClusterAttributes cluster attributes
// swagger:model ClusterAttributes
type ClusterAttributes struct {

	// autoscale
	Autoscale *AutoScale `json:"autoscale,omitempty"`

	// autotermination minutes
	AutoterminationMinutes int32 `json:"autotermination_minutes,omitempty"`

	// aws attributes
	AwsAttributes *AwsAttributes `json:"aws_attributes,omitempty"`

	// cluster log conf
	ClusterLogConf *ClusterLogConf `json:"cluster_log_conf,omitempty"`

	// cluster name
	ClusterName string `json:"cluster_name,omitempty"`

	// custom tags
	CustomTags ClusterTag `json:"custom_tags,omitempty"`

	// docker image
	DockerImage *DockerImage `json:"docker_image,omitempty"`

	// driver node type id
	DriverNodeTypeID string `json:"driver_node_type_id,omitempty"`

	// enable elastic disk
	EnableElasticDisk bool `json:"enable_elastic_disk,omitempty"`

	// idempotency token
	IdempotencyToken string `json:"idempotency_token,omitempty"`

	// init scripts
	InitScripts []*InitScriptInfo `json:"init_scripts"`

	// instance pool id
	InstancePoolID string `json:"instance_pool_id,omitempty"`

	// node type id
	NodeTypeID string `json:"node_type_id,omitempty"`

	// num workers
	NumWorkers int64 `json:"num_workers,omitempty"`

	// spark conf
	SparkConf SparkConfPair `json:"spark_conf,omitempty"`

	// spark env vars
	SparkEnvVars SparkEnvPair `json:"spark_env_vars,omitempty"`

	// spark version
	SparkVersion string `json:"spark_version,omitempty"`

	// ssh public keys
	SSHPublicKeys []string `json:"ssh_public_keys"`
}

// Validate validates this cluster attributes
func (m *ClusterAttributes) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateAutoscale(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateAwsAttributes(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateClusterLogConf(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateCustomTags(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateDockerImage(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateInitScripts(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateSparkConf(formats); err != nil {
		res = append(res, err)
	}

	if err := m.validateSparkEnvVars(formats); err != nil {
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}

func (m *ClusterAttributes) validateAutoscale(formats strfmt.Registry) error {

	if swag.IsZero(m.Autoscale) { // not required
		return nil
	}

	if m.Autoscale != nil {
		if err := m.Autoscale.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("autoscale")
			}
			return err
		}
	}

	return nil
}

func (m *ClusterAttributes) validateAwsAttributes(formats strfmt.Registry) error {

	if swag.IsZero(m.AwsAttributes) { // not required
		return nil
	}

	if m.AwsAttributes != nil {
		if err := m.AwsAttributes.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("aws_attributes")
			}
			return err
		}
	}

	return nil
}

func (m *ClusterAttributes) validateClusterLogConf(formats strfmt.Registry) error {

	if swag.IsZero(m.ClusterLogConf) { // not required
		return nil
	}

	if m.ClusterLogConf != nil {
		if err := m.ClusterLogConf.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("cluster_log_conf")
			}
			return err
		}
	}

	return nil
}

func (m *ClusterAttributes) validateCustomTags(formats strfmt.Registry) error {

	if swag.IsZero(m.CustomTags) { // not required
		return nil
	}

	if err := m.CustomTags.Validate(formats); err != nil {
		if ve, ok := err.(*errors.Validation); ok {
			return ve.ValidateName("custom_tags")
		}
		return err
	}

	return nil
}

func (m *ClusterAttributes) validateDockerImage(formats strfmt.Registry) error {

	if swag.IsZero(m.DockerImage) { // not required
		return nil
	}

	if m.DockerImage != nil {
		if err := m.DockerImage.Validate(formats); err != nil {
			if ve, ok := err.(*errors.Validation); ok {
				return ve.ValidateName("docker_image")
			}
			return err
		}
	}

	return nil
}

func (m *ClusterAttributes) validateInitScripts(formats strfmt.Registry) error {

	if swag.IsZero(m.InitScripts) { // not required
		return nil
	}

	for i := 0; i < len(m.InitScripts); i++ {
		if swag.IsZero(m.InitScripts[i]) { // not required
			continue
		}

		if m.InitScripts[i] != nil {
			if err := m.InitScripts[i].Validate(formats); err != nil {
				if ve, ok := err.(*errors.Validation); ok {
					return ve.ValidateName("init_scripts" + "." + strconv.Itoa(i))
				}
				return err
			}
		}

	}

	return nil
}

func (m *ClusterAttributes) validateSparkConf(formats strfmt.Registry) error {

	if swag.IsZero(m.SparkConf) { // not required
		return nil
	}

	if err := m.SparkConf.Validate(formats); err != nil {
		if ve, ok := err.(*errors.Validation); ok {
			return ve.ValidateName("spark_conf")
		}
		return err
	}

	return nil
}

func (m *ClusterAttributes) validateSparkEnvVars(formats strfmt.Registry) error {

	if swag.IsZero(m.SparkEnvVars) { // not required
		return nil
	}

	if err := m.SparkEnvVars.Validate(formats); err != nil {
		if ve, ok := err.(*errors.Validation); ok {
			return ve.ValidateName("spark_env_vars")
		}
		return err
	}

	return nil
}

// MarshalBinary interface implementation
func (m *ClusterAttributes) MarshalBinary() ([]byte, error) {
	if m == nil {
		return nil, nil
	}
	return swag.WriteJSON(m)
}

// UnmarshalBinary interface implementation
func (m *ClusterAttributes) UnmarshalBinary(b []byte) error {
	var res ClusterAttributes
	if err := swag.ReadJSON(b, &res); err != nil {
		return err
	}
	*m = res
	return nil
}
